{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib created a temporary config/cache directory at /tmp/matplotlib-lb6gqxzo because the default path (/home/jovyan/.cache/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import os\n",
    "from pettingzoo.butterfly import cooperative_pong_v2\n",
    "import supersuit as ss\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from stable_baselines3.ppo import CnnPolicy\n",
    "from stable_baselines3 import PPO\n",
    "\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "from stable_baselines3.common.results_plotter import load_results, ts2xy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = cooperative_pong_v2.parallel_env(ball_speed=9, left_paddle_speed=12, right_paddle_speed=12, cake_paddle=False, max_cycles=2000, bounce_randomness=False) #create env\n",
    "agents= ['paddle_0', 'paddle_1'] #name agents\n",
    "env = ss.color_reduction_v0(env, mode='B') #convert to grayscale for less computation\n",
    "env = ss.resize_v0(env, x_size=84, y_size=84) #resive\n",
    "env = ss.frame_stack_v1(env, 4)#stack 4 frames together to see velocity/direction\n",
    "env = ss.pettingzoo_env_to_vec_env_v0(env) #convert to vec env\n",
    "env = ss.concat_vec_envs_v0(env, 8, num_cpus=1, base_class='stable_baselines3') #parallelize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env in a VecTransposeImage.\n"
     ]
    }
   ],
   "source": [
    "model = PPO(CnnPolicy, env,  learning_rate=0.0003, n_steps=2048, batch_size=64, n_epochs=10, gamma=0.99, gae_lambda=0.95, clip_range=0.2,\n",
    "            clip_range_vf=1, ent_coef=0.0, vf_coef=0.5, max_grad_norm=0.5, use_sde=False, sde_sample_freq=- 1, target_kl=None, \n",
    "            tensorboard_log=None, create_eval_env=False, policy_kwargs=None, verbose=1, seed=314, device='auto', _init_setup_model=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 687      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 5        |\n",
      "|    total_timesteps | 4096     |\n",
      "| train/             |          |\n",
      "|    learning_rate   | 0.0003   |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bd6fr/.local/lib/python3.7/site-packages/stable_baselines3/common/save_util.py:276: UserWarning: Path 'log' does not exist. Will create it.\n",
      "  warnings.warn(f\"Path '{path.parent}' does not exist. Will create it.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log/2048 complete!\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 650           |\n",
      "|    iterations           | 1             |\n",
      "|    time_elapsed         | 6             |\n",
      "|    total_timesteps      | 4096          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | -0.0033580007 |\n",
      "|    clip_fraction        | 0.121         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    clip_range_vf        | 1             |\n",
      "|    entropy_loss         | -1.09         |\n",
      "|    explained_variance   | -0.000185     |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 104           |\n",
      "|    n_updates            | 10            |\n",
      "|    policy_gradient_loss | -0.0189       |\n",
      "|    value_loss           | 289           |\n",
      "-------------------------------------------\n",
      "log/4096 complete!\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 695          |\n",
      "|    iterations           | 1            |\n",
      "|    time_elapsed         | 5            |\n",
      "|    total_timesteps      | 4096         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | -0.010584453 |\n",
      "|    clip_fraction        | 0.36         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    clip_range_vf        | 1            |\n",
      "|    entropy_loss         | -1.06        |\n",
      "|    explained_variance   | 0.00046      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 129          |\n",
      "|    n_updates            | 20           |\n",
      "|    policy_gradient_loss | -0.0373      |\n",
      "|    value_loss           | 250          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 327         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 25          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016667232 |\n",
      "|    clip_fraction        | 0.46        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    clip_range_vf        | 1           |\n",
      "|    entropy_loss         | -1.03       |\n",
      "|    explained_variance   | -0.0365     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 116         |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0247     |\n",
      "|    value_loss           | 226         |\n",
      "-----------------------------------------\n",
      "log/6144 complete!\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 697         |\n",
      "|    iterations           | 1           |\n",
      "|    time_elapsed         | 5           |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018942345 |\n",
      "|    clip_fraction        | 0.522       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    clip_range_vf        | 1           |\n",
      "|    entropy_loss         | -1          |\n",
      "|    explained_variance   | -0.0197     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 94.7        |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0408     |\n",
      "|    value_loss           | 193         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 321         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 25          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.040928036 |\n",
      "|    clip_fraction        | 0.574       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    clip_range_vf        | 1           |\n",
      "|    entropy_loss         | -0.959      |\n",
      "|    explained_variance   | -0.268      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 89.6        |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0436     |\n",
      "|    value_loss           | 144         |\n",
      "-----------------------------------------\n",
      "log/8192 complete!\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 696         |\n",
      "|    iterations           | 1           |\n",
      "|    time_elapsed         | 5           |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.081737176 |\n",
      "|    clip_fraction        | 0.589       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    clip_range_vf        | 1           |\n",
      "|    entropy_loss         | -0.934      |\n",
      "|    explained_variance   | -0.0979     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 31.1        |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0323     |\n",
      "|    value_loss           | 99.2        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 321        |\n",
      "|    iterations           | 2          |\n",
      "|    time_elapsed         | 25         |\n",
      "|    total_timesteps      | 8192       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.12324673 |\n",
      "|    clip_fraction        | 0.557      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    clip_range_vf        | 1          |\n",
      "|    entropy_loss         | -0.868     |\n",
      "|    explained_variance   | 0.0169     |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 30.3       |\n",
      "|    n_updates            | 70         |\n",
      "|    policy_gradient_loss | -0.00959   |\n",
      "|    value_loss           | 52.9       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 271        |\n",
      "|    iterations           | 3          |\n",
      "|    time_elapsed         | 45         |\n",
      "|    total_timesteps      | 12288      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.10571733 |\n",
      "|    clip_fraction        | 0.494      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    clip_range_vf        | 1          |\n",
      "|    entropy_loss         | -0.879     |\n",
      "|    explained_variance   | 0.00848    |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 25         |\n",
      "|    n_updates            | 80         |\n",
      "|    policy_gradient_loss | 0.000168   |\n",
      "|    value_loss           | 54.2       |\n",
      "----------------------------------------\n",
      "log/10240 complete!\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 689        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 5          |\n",
      "|    total_timesteps      | 4096       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.08137672 |\n",
      "|    clip_fraction        | 0.446      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    clip_range_vf        | 1          |\n",
      "|    entropy_loss         | -0.9       |\n",
      "|    explained_variance   | 0.0846     |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 16         |\n",
      "|    n_updates            | 90         |\n",
      "|    policy_gradient_loss | -0.00153   |\n",
      "|    value_loss           | 48.3       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 324        |\n",
      "|    iterations           | 2          |\n",
      "|    time_elapsed         | 25         |\n",
      "|    total_timesteps      | 8192       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.08106826 |\n",
      "|    clip_fraction        | 0.467      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    clip_range_vf        | 1          |\n",
      "|    entropy_loss         | -0.89      |\n",
      "|    explained_variance   | 0.139      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 28.7       |\n",
      "|    n_updates            | 100        |\n",
      "|    policy_gradient_loss | -0.00119   |\n",
      "|    value_loss           | 51.5       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 276         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 44          |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.099311024 |\n",
      "|    clip_fraction        | 0.457       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    clip_range_vf        | 1           |\n",
      "|    entropy_loss         | -0.905      |\n",
      "|    explained_variance   | 0.19        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 18.5        |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.00831    |\n",
      "|    value_loss           | 44.6        |\n",
      "-----------------------------------------\n",
      "log/12288 complete!\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 699        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 5          |\n",
      "|    total_timesteps      | 4096       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.08599268 |\n",
      "|    clip_fraction        | 0.465      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    clip_range_vf        | 1          |\n",
      "|    entropy_loss         | -0.886     |\n",
      "|    explained_variance   | 0.139      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 28.8       |\n",
      "|    n_updates            | 120        |\n",
      "|    policy_gradient_loss | -0.0092    |\n",
      "|    value_loss           | 59.1       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 327        |\n",
      "|    iterations           | 2          |\n",
      "|    time_elapsed         | 25         |\n",
      "|    total_timesteps      | 8192       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.07790048 |\n",
      "|    clip_fraction        | 0.417      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    clip_range_vf        | 1          |\n",
      "|    entropy_loss         | -0.876     |\n",
      "|    explained_variance   | 0.28       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 18.1       |\n",
      "|    n_updates            | 130        |\n",
      "|    policy_gradient_loss | 0.00139    |\n",
      "|    value_loss           | 52.8       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 276        |\n",
      "|    iterations           | 3          |\n",
      "|    time_elapsed         | 44         |\n",
      "|    total_timesteps      | 12288      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.08866194 |\n",
      "|    clip_fraction        | 0.432      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    clip_range_vf        | 1          |\n",
      "|    entropy_loss         | -0.886     |\n",
      "|    explained_variance   | 0.139      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 36.2       |\n",
      "|    n_updates            | 140        |\n",
      "|    policy_gradient_loss | -0.0126    |\n",
      "|    value_loss           | 56.4       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 256        |\n",
      "|    iterations           | 4          |\n",
      "|    time_elapsed         | 63         |\n",
      "|    total_timesteps      | 16384      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.07942369 |\n",
      "|    clip_fraction        | 0.441      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    clip_range_vf        | 1          |\n",
      "|    entropy_loss         | -0.902     |\n",
      "|    explained_variance   | 0.119      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 16.1       |\n",
      "|    n_updates            | 150        |\n",
      "|    policy_gradient_loss | -0.00449   |\n",
      "|    value_loss           | 48.1       |\n",
      "----------------------------------------\n",
      "log/14336 complete!\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 691         |\n",
      "|    iterations           | 1           |\n",
      "|    time_elapsed         | 5           |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.068725616 |\n",
      "|    clip_fraction        | 0.389       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    clip_range_vf        | 1           |\n",
      "|    entropy_loss         | -0.895      |\n",
      "|    explained_variance   | 0.121       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 18.8        |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.00778    |\n",
      "|    value_loss           | 57.9        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 324        |\n",
      "|    iterations           | 2          |\n",
      "|    time_elapsed         | 25         |\n",
      "|    total_timesteps      | 8192       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06250272 |\n",
      "|    clip_fraction        | 0.384      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    clip_range_vf        | 1          |\n",
      "|    entropy_loss         | -0.894     |\n",
      "|    explained_variance   | 0.0255     |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 43.8       |\n",
      "|    n_updates            | 170        |\n",
      "|    policy_gradient_loss | -0.00642   |\n",
      "|    value_loss           | 50.2       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 275        |\n",
      "|    iterations           | 3          |\n",
      "|    time_elapsed         | 44         |\n",
      "|    total_timesteps      | 12288      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.07301471 |\n",
      "|    clip_fraction        | 0.459      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    clip_range_vf        | 1          |\n",
      "|    entropy_loss         | -0.834     |\n",
      "|    explained_variance   | 0.12       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 25.1       |\n",
      "|    n_updates            | 180        |\n",
      "|    policy_gradient_loss | -0.0256    |\n",
      "|    value_loss           | 53.1       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 256        |\n",
      "|    iterations           | 4          |\n",
      "|    time_elapsed         | 63         |\n",
      "|    total_timesteps      | 16384      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.11010548 |\n",
      "|    clip_fraction        | 0.426      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    clip_range_vf        | 1          |\n",
      "|    entropy_loss         | -0.835     |\n",
      "|    explained_variance   | 0.0274     |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 33.3       |\n",
      "|    n_updates            | 190        |\n",
      "|    policy_gradient_loss | 0.00283    |\n",
      "|    value_loss           | 61.5       |\n",
      "----------------------------------------\n",
      "log/16384 complete!\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 683        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 5          |\n",
      "|    total_timesteps      | 4096       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.09948968 |\n",
      "|    clip_fraction        | 0.419      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    clip_range_vf        | 1          |\n",
      "|    entropy_loss         | -0.859     |\n",
      "|    explained_variance   | 0.0871     |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 25.4       |\n",
      "|    n_updates            | 200        |\n",
      "|    policy_gradient_loss | -0.0202    |\n",
      "|    value_loss           | 47.4       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 316        |\n",
      "|    iterations           | 2          |\n",
      "|    time_elapsed         | 25         |\n",
      "|    total_timesteps      | 8192       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.10863008 |\n",
      "|    clip_fraction        | 0.403      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    clip_range_vf        | 1          |\n",
      "|    entropy_loss         | -0.82      |\n",
      "|    explained_variance   | 0.139      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 23.7       |\n",
      "|    n_updates            | 210        |\n",
      "|    policy_gradient_loss | -0.00151   |\n",
      "|    value_loss           | 47.7       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 272        |\n",
      "|    iterations           | 3          |\n",
      "|    time_elapsed         | 45         |\n",
      "|    total_timesteps      | 12288      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.13631256 |\n",
      "|    clip_fraction        | 0.428      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    clip_range_vf        | 1          |\n",
      "|    entropy_loss         | -0.797     |\n",
      "|    explained_variance   | 0.304      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 30         |\n",
      "|    n_updates            | 220        |\n",
      "|    policy_gradient_loss | -0.00369   |\n",
      "|    value_loss           | 59.3       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 253         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 64          |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.104039356 |\n",
      "|    clip_fraction        | 0.425       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    clip_range_vf        | 1           |\n",
      "|    entropy_loss         | -0.809      |\n",
      "|    explained_variance   | 0.199       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 21.6        |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.0026     |\n",
      "|    value_loss           | 54.2        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 243        |\n",
      "|    iterations           | 5          |\n",
      "|    time_elapsed         | 83         |\n",
      "|    total_timesteps      | 20480      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.08370878 |\n",
      "|    clip_fraction        | 0.388      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    clip_range_vf        | 1          |\n",
      "|    entropy_loss         | -0.77      |\n",
      "|    explained_variance   | 0.329      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 32.7       |\n",
      "|    n_updates            | 240        |\n",
      "|    policy_gradient_loss | -0.00438   |\n",
      "|    value_loss           | 50.7       |\n",
      "----------------------------------------\n",
      "log/18432 complete!\n"
     ]
    }
   ],
   "source": [
    "for steps in range(2048,(20480*5),2048):\n",
    "    model.learn(total_timesteps = steps)\n",
    "    \n",
    "    policy = str(steps)\n",
    "    model.save(policy)\n",
    "    print(policy + ' complete!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set up test env\n",
    "env1 = cooperative_pong_v2.parallel_env(ball_speed=9, left_paddle_speed=12, right_paddle_speed=12, cake_paddle=False, max_cycles=2000, bounce_randomness=False) #create env\n",
    "agents= ['paddle_0', 'paddle_1'] #name agents\n",
    "env1 = ss.color_reduction_v0(env1, mode='B') #convert to grayscale for less computation\n",
    "env1 = ss.resize_v0(env1, x_size=84, y_size=84) #resive\n",
    "env1 = ss.frame_stack_v1(env1, 4)#stack 4 frames together to see velocity/direction\n",
    "env1 = ss.pettingzoo_env_to_vec_env_v0(env1) #convert to vec env\n",
    "env1 = ss.concat_vec_envs_v0(env1, 1, num_cpus=0, base_class='stable_baselines3') #parallelize, only 1 env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(columns = ['num_training_steps', 'avg_reward'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping the env in a VecTransposeImage.\n",
      "Wrapping the env in a VecTransposeImage.\n",
      "Wrapping the env in a VecTransposeImage.\n",
      "Wrapping the env in a VecTransposeImage.\n",
      "Wrapping the env in a VecTransposeImage.\n",
      "Wrapping the env in a VecTransposeImage.\n",
      "Wrapping the env in a VecTransposeImage.\n",
      "Wrapping the env in a VecTransposeImage.\n",
      "Wrapping the env in a VecTransposeImage.\n"
     ]
    }
   ],
   "source": [
    "num_episodes = range(100)\n",
    "\n",
    "for count, filename in enumerate(os.listdir()):\n",
    "    if filename.endswith(\".zip\"):\n",
    "        model = PPO.load(filename.split('.')[0], env=env1)\n",
    "        reward_per_ep = []\n",
    "\n",
    "        for ep in num_episodes:\n",
    "\n",
    "            rewards = []\n",
    "            steps = 0\n",
    "\n",
    "\n",
    "            obs = env1.reset()\n",
    "            done = np.array([0,0])\n",
    "\n",
    "            while all(done) != 1:\n",
    "                action, _states = model.predict(obs)\n",
    "                obs, reward, done, info = env1.step(action)\n",
    "                steps+=1\n",
    "                rewards.append(reward[0])\n",
    "\n",
    "            reward_per_ep.append(sum(rewards)/len(rewards))\n",
    "\n",
    "\n",
    "        results = results.append({'num_training_steps' : int(filename.split('.')[0]), 'avg_reward' : sum(reward_per_ep)/len(reward_per_ep)}, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_training_steps</th>\n",
       "      <th>avg_reward</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2048.0</td>\n",
       "      <td>-1.127084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2048.0</td>\n",
       "      <td>-1.182053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4096.0</td>\n",
       "      <td>-1.117930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4096.0</td>\n",
       "      <td>-0.951497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>6144.0</td>\n",
       "      <td>-1.085327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6144.0</td>\n",
       "      <td>-1.309513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8192.0</td>\n",
       "      <td>-0.966854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>8192.0</td>\n",
       "      <td>-0.985863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10240.0</td>\n",
       "      <td>-0.896531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>10240.0</td>\n",
       "      <td>-1.064802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12288.0</td>\n",
       "      <td>-1.114083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>12288.0</td>\n",
       "      <td>-0.999584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>14336.0</td>\n",
       "      <td>-1.251335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14336.0</td>\n",
       "      <td>-1.101667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16384.0</td>\n",
       "      <td>-1.079804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>16384.0</td>\n",
       "      <td>-1.025437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>18432.0</td>\n",
       "      <td>-1.276155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>18432.0</td>\n",
       "      <td>-0.998621</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    num_training_steps  avg_reward\n",
       "8               2048.0   -1.127084\n",
       "17              2048.0   -1.182053\n",
       "10              4096.0   -1.117930\n",
       "1               4096.0   -0.951497\n",
       "9               6144.0   -1.085327\n",
       "0               6144.0   -1.309513\n",
       "6               8192.0   -0.966854\n",
       "15              8192.0   -0.985863\n",
       "3              10240.0   -0.896531\n",
       "12             10240.0   -1.064802\n",
       "4              12288.0   -1.114083\n",
       "13             12288.0   -0.999584\n",
       "5              14336.0   -1.251335\n",
       "14             14336.0   -1.101667\n",
       "2              16384.0   -1.079804\n",
       "11             16384.0   -1.025437\n",
       "7              18432.0   -1.276155\n",
       "16             18432.0   -0.998621"
      ]
     },
     "execution_count": 417,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.sort_values(by=['num_training_steps'])\n",
    "results.to_csv('results_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DS 5559",
   "language": "python",
   "name": "ds5559"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
